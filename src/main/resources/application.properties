# web port
server.port=8080
#MongoDB????
spring.data.mongodb.uri=mongodb://localhost:27017/chat_memory_db
# ???????
spring.datasource.url=jdbc:mysql://localhost:3306/guiguxiaozhi?useUnicode=true&characterEncoding=UTF-8&serverTimezone=Asia/Shanghai&useSSL=false
spring.datasource.username=root
spring.datasource.password=123456
spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver
# ?? SQL ????
mybatis-plus.configuration.log-impl=org.apache.ibatis.logging.stdout.StdOutImpl
#1.langchain4j
#langchain4j.open-ai.chat-model.base-url=http://langchain4j.dev/demo/openai/v1
#langchain4j.open-ai.chat-model.api-key=demo
#langchain4j.open-ai.chat-model.model-name=gpt-4o-mini
#langchain4j.open-ai.chat-model.log-requests=true
#langchain4j.open-ai.chat-model.log-responses=true
#2.langchain4j deepseek
#langchain4j.open-ai.chat-model.base-url=https://api.deepseek.com/v1
#langchain4j.open-ai.chat-model.api-key=
#langchain4j.open-ai.chat-model.model-name=deepseek-chat
#langchain4j.open-ai.chat-model.log-requests=true
#langchain4j.open-ai.chat-model.log-responses=true
#3.ollama
langchain4j.ollama.chat-model.base-url=http://localhost:11434
langchain4j.ollama.chat-model.model-name=qwen3:1.7b
langchain4j.ollama.chat-model.temperature=0.2
#langchain4j.ollama.chat-model.timeout=100000000
#langchain4j.ollama.chat-model.log-requests=true
#langchain4j.ollama.chat-model.log-responses=true
#4.??
#langchain4j.community.dashscope.chat-model.api-key=${DASH_SCOPE_API_KEY}
#langchain4j.community.dashscope.chat-model.model-name=qwen-plus
#????????-??????-v3
#langchain4j.community.dashscope.embedding-model.api-key=${DASH_SCOPE_API_KEY}
#langchain4j.community.dashscope.embedding-model.model-name=text-embedding-v3
#????????-????
langchain4j.community.dashscope.streaming-chat-model.api-key=${DASH_SCOPE_API_KEY}
langchain4j.community.dashscope.streaming-chat-model.model-name=qwen-max
#logging.level.root=debug
# ollama
langchain4j.ollama.streaming-chat-model.base-url=http://localhost:11434
langchain4j.ollama.streaming-chat-model.model-name=qwen3:1.7b
#langchain4j.ollama.streaming-chat-model.model-name=granite3.3:2b
#langchain4j.ollama.streaming-chat-model.model-name=cogito:3b
langchain4j.ollama.streaming-chat-model.temperature=0.2
langchain4j.ollama.streaming-chat-model.timeout=1000000
langchain4j.ollama.embedding-model.base-url=http://localhost:11434
langchain4j.ollama.embedding-model.model-name=nomic-embed-text
langchain4j.ollama.embedding-model.timeout=10000000

spring.elasticsearch.uris: http://192.168.10.188:9200
spring.elasticsearch.connection-timeout: 10000
spring.elasticsearch.socket-timeout: 6000
#spring.elasticsearch.username=elastic
#spring.elasticsearch.password=123456
